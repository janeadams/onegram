{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import socket\n",
    "from subprocess import Popen, PIPE\n",
    "import getpass\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import gzip\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas\n",
    "import argparse\n",
    "import datetime\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from multiprocessing import Pool\n",
    "plt.switch_backend('agg')\n",
    "from pymongo import MongoClient\n",
    "from pymongo.collation import Collation, CollationStrength\n",
    "from datetime import timedelta, date\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "password = os.getenv(\"PASSWORD\")\n",
    "username = os.getenv(\"USERNAME\")\n",
    "location = os.getenv(\"LOCATION\")[6:]\n",
    "collection = os.getenv(\"COLLECTION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c28609abedcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-c28609abedcd>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tweet'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musername\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'word'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_timeseries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-c28609abedcd>\u001b[0m in \u001b[0;36mquery_timeseries\u001b[0;34m(self, query, word, max_range)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mdata_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                 \u001b[0mdata_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'counts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'freq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_array\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/test_env/lib/python3.7/site-packages/pymongo/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__manipulate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0m_db\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__collection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m                 return _db._fix_outgoing(self.__data.popleft(),\n\u001b[0m\u001b[1;32m   1193\u001b[0m                                          self.__collection)\n\u001b[1;32m   1194\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date).days)):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "\n",
    "class Query:\n",
    "    \"\"\"Class to work with 1-gram db\"\"\"\n",
    "\n",
    "    def __init__(self, username, pwd, db, lang):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        username: mongoDB user\n",
    "        pwd: mongoDB password\n",
    "        query: mongo formatted\n",
    "        \"\"\"\n",
    " \n",
    "        #password = getpass.getpass('password:') # those with guest access\n",
    "        #if socket.gethostname() != 'hydra.uvm.edu':\n",
    "        #    proc = Popen(['./port_forward.sh'], stdin=PIPE)\n",
    "            # proc.communicate(input=password.encode('utf-8')) # also for Guests\n",
    "\n",
    "        client = MongoClient('mongodb://%s:%s@hydra.uvm.edu:27017' % (username, pwd))\n",
    "        db = client[location]\n",
    "        self.tweets = db[collection]\n",
    "        self.lang = lang\n",
    "        return\n",
    "    \n",
    "    def query_zipf_dist(self, starttime, endtime=None):\n",
    "        \"\"\" Query the database and return daily zipf files (word, count, rank, frequency)\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        starttime (datetime object): the start date of the range for the zipf data\n",
    "        endtime (optional) (datetime object): the end date of the range for the zipf data         \n",
    "\n",
    "        \"\"\"\n",
    "        if not endtime:\n",
    "            query = {'time':starttime} \n",
    "        else:\n",
    "            query =  {'time':{'$lte':starttime,'$gte':endtime}}\n",
    "                \n",
    "        cursor = self.tweets.find(query)\n",
    "\n",
    "        results = pd.DataFrame.from_dict([x for x in cursor])\n",
    "        \n",
    "        return results.drop(['_id','time'], axis=1)\n",
    "        \n",
    "\n",
    "    def query_timeseries(self, query=None, word=None, max_range=False):\n",
    "        \"\"\" query database for n-gram timeseries, return pandas dataframe\\\n",
    "        :param query: json-like query for mongo\n",
    "        :param word: word to query\n",
    "        :param max_range: flag to query over default date range\n",
    "        :return: pandas dataframe of count, rank, and frequency over time for an n-gram\"\"\"\n",
    "        if max_range:\n",
    "            index = pd.date_range(start=datetime.datetime(2008,9,1),end=datetime.date.today(),freq='D')\n",
    "        else:\n",
    "            data_array = []\n",
    "            for i in self.tweets.find(query):\n",
    "                data_array.append([i['time'],int(i['counts']), float(i['freq'])])\n",
    "            if len(data_array) == 0:\n",
    "                return\n",
    "            data = np.array(data_array)\n",
    "            data = data[data[:,0].argsort()]\n",
    "            \n",
    "            index = pd.date_range(start=data[0,0], end=data[-1,0], freq='D')\n",
    "        data2 = np.zeros((len(index), 3))\n",
    "        data2[:,1] = np.nan\n",
    "        index_dict = {x.to_pydatetime():i for i,x in enumerate(index)}\n",
    "        for i in self.tweets.find(query):\n",
    "            try:\n",
    "                data2[index_dict[i['time']],:] = int(i['counts']),np.nan,float(i['freq'])\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "        return  pd.DataFrame(data=data2,\n",
    "                    index=index)\n",
    "\n",
    "    def query_insensitive_timeseries(self, query=None, word=None, max_range=False):\n",
    "        \"\"\" query database for n-gram timeseries, return pandas dataframe\\\n",
    "        :param query: json-like query for mongo\n",
    "        :param word: word to query\n",
    "        :param max_range: flag to query over default date range\n",
    "        :return: pandas dataframe of count, rank, and frequency over time for an n-gram\"\"\"\n",
    "        if max_range:\n",
    "            index = pd.date_range(start=datetime.datetime(2008,9,1),end=datetime.date.today(),freq='D')\n",
    "        else:\n",
    "            data_array = []\n",
    "            for i in self.tweets.find(query).sort('word').collation(Collation(locale=self.lang,strength=CollationStrength.SECONDARY)):\n",
    "                data_array.append([i['time'],int(i['counts']), float(i['rank']), float(i['freq'])])\n",
    "            if len(data_array) == 0:\n",
    "                return\n",
    "            data = np.array(data_array)\n",
    "            data = data[data[:,0].argsort()]\n",
    "\n",
    "            index = pd.date_range(start=data[0,0], end=data[-1,0], freq='D')\n",
    "        data2 = np.zeros((len(index), 3))\n",
    "        data2[:,1] = np.nan\n",
    "        index_dict = {x.to_pydatetime():i for i,x in enumerate(index)}\n",
    "        for i in self.tweets.find(query).sort('word').collation(Collation(locale=self.lang,strength=CollationStrength.SECONDARY)):\n",
    "            try:\n",
    "                data2[index_dict[i['time']],:] += int(i['counts']),int(i['rank']),float(i['freq'])\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "        return  pd.DataFrame(data=data2,\n",
    "                    index=index)\n",
    "\n",
    "    def query_languages(self, lang):\n",
    "        \"\"\" queries database and returns pandas dataframe\n",
    "        :param query: \n",
    "        :param gt_days: minimum number of days in the database\n",
    "        :return: list of n-grams matching pattern \"\"\"\n",
    "        index = pd.date_range(start=datetime.datetime(2008,9,1),end=datetime.date.today(),freq='D')\n",
    "        \n",
    "        data2 = np.zeros((len(index), 6))\n",
    "        data2[:,:] = np.nan\n",
    "        index_dict = {x.to_pydatetime():i for i,x in enumerate(index)}\n",
    "        query = {'language':lang }\n",
    "        for i in self.tweets.find(query):\n",
    "            try:\n",
    "                data2[index_dict[i['date']],:] = i['ft_count'],i['ft_rank'],i['ft_freq'],i['tw_count'],i['tw_rank'],i['tw_freq']\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "        return  pd.DataFrame(data=data2,\n",
    "                    index=index)\n",
    "\n",
    "\n",
    "    def query_regex(self, query, gt_days=1):\n",
    "        \"\"\" queries database and returns a list of unique strings matching a regex\n",
    "        :param query: json-like query for mongo\n",
    "        :param gt_days: minimum number of days in the database\n",
    "        :return: list of n-grams matching pattern \"\"\"\n",
    "        \n",
    "        word_dic = {}\n",
    "        for i in self.tweets.find(query):\n",
    "            if i['word'] in word_dic:\n",
    "                word_dic[i['word']] +=1 \n",
    "            else:\n",
    "                word_dic[i['word']] = 1 \n",
    "        return [i for i,value in word_dic.items() if value > gt_days]\n",
    "\n",
    "\n",
    "    def tweet_query(self, query):\n",
    "        for i in self.tweets.find(query):\n",
    "            yield i\n",
    "\n",
    "    def stdout_timeseries(self):\n",
    "        \"\"\"Prints timeseries data to screen\"\"\"\n",
    "        data = self.data\n",
    "        df = pd.DataFrame(data)\n",
    "        data1 = [datetime.datetime.strftime(i, format=\"%Y-%m-%d\") for i in data[:,0]]\n",
    "        for row in self.data2.itertuples():\n",
    "            print(datetime.datetime.strftime(row[0],format=\"%Y-%m-%d\"), int(row[1]), int(row[2]), row[3])\n",
    "        return\n",
    "\n",
    "\n",
    "    def timeseries_tofile(self):\n",
    "        try:\n",
    "            self.data2.to_csv(f'output/{word}.txt', header=None, sep=' ')\n",
    "            print(f'{timeit.default_timer() - start} seconds')\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        return\n",
    "    \n",
    "def main():\n",
    "    word = 'tweet'\n",
    "    query = Query(username, password, {'word' : word}, word)\n",
    "    data = query.query_timeseries()\n",
    "    print(data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TestEnv)",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
